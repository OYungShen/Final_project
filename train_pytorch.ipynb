{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import pytorch_dataset\n",
    "from pytorch_model import CNN\n",
    "\n",
    "# Hyper Parameters\n",
    "num_epochs = 40\n",
    "batch_size = 80\n",
    "learning_rate = 0.001\n",
    "use_cuda=True\n",
    "def main():\n",
    "    min_loss = 9999\n",
    "    device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "    cnn = CNN().to(device)\n",
    "    cnn.train()\n",
    "    print('init net')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the Model\n",
    "    train_dataloader = pytorch_dataset.get_train_data_loader()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            images = Variable(images).to(device)\n",
    "            labels1 = Variable(labels['label1'].float()).to(device)\n",
    "            labels2 = Variable(labels['label2'].float()).to(device)\n",
    "            labels3 = Variable(labels['label3'].float()).to(device)\n",
    "            labels4 = Variable(labels['label4'].float()).to(device)\n",
    "            labels5 = Variable(labels['label5'].float()).to(device)\n",
    "            out1,out2,out3,out4, out5 = cnn(images)\n",
    "            #out = cnn(images)\n",
    "\n",
    "            # print(predict_labels.type)\n",
    "            # print(labels.type)\n",
    "            loss1 = criterion(out1, torch.max(labels1, 1)[1])\n",
    "            loss2 = criterion(out2, torch.max(labels2, 1)[1])\n",
    "            loss3 = criterion(out3, torch.max(labels3, 1)[1])\n",
    "            loss4 = criterion(out4, torch.max(labels4, 1)[1])\n",
    "            loss5 = criterion(out5, torch.max(labels5, 1)[1])\n",
    "            loss = (loss1+loss2+loss3+loss4+loss5)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
    "            if (i+1) % 100 == 0:\n",
    "                torch.save(cnn.state_dict(), \"./model.pkl\")   #current is model.pkl\n",
    "                print(\"save model\")\n",
    "            if min_loss > loss.item():\n",
    "                min_loss = loss.item()\n",
    "                torch.save(cnn.state_dict(), \"./model_best.pkl\")   #current is model.pkl\n",
    "                print(\"save best model\")\n",
    "        print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
    "    torch.save(cnn.state_dict(), \"./model.pkl\")   #current is model.pkl\n",
    "    print(\"save last model\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import pytorch_dataset\n",
    "from pytorch_model import CNN\n",
    "\n",
    "# Hyper Parameters\n",
    "num_epochs = 300\n",
    "batch_size = 80\n",
    "learning_rate = 0.001\n",
    "use_cuda=True\n",
    "\n",
    "def main():\n",
    "    min_loss = 9999\n",
    "    device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "    cnn = CNN().to(device)\n",
    "    cnn.train()\n",
    "    cnn.load_state_dict(torch.load('model_best.pkl'))\n",
    "    print('init net')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the Model\n",
    "    train_dataloader = pytorch_dataset.get_transfer_data_loader()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            images = Variable(images).to(device)\n",
    "            labels1 = Variable(labels['label1'].float()).to(device)\n",
    "            labels2 = Variable(labels['label2'].float()).to(device)\n",
    "            labels3 = Variable(labels['label3'].float()).to(device)\n",
    "            labels4 = Variable(labels['label4'].float()).to(device)\n",
    "            labels5 = Variable(labels['label5'].float()).to(device)\n",
    "            out1,out2,out3,out4, out5 = cnn(images)\n",
    "            #out = cnn(images)\n",
    "\n",
    "            # print(predict_labels.type)\n",
    "            # print(labels.type)\n",
    "            loss1 = criterion(out1, torch.max(labels1, 1)[1])\n",
    "            loss2 = criterion(out2, torch.max(labels2, 1)[1])\n",
    "            loss3 = criterion(out3, torch.max(labels3, 1)[1])\n",
    "            loss4 = criterion(out4, torch.max(labels4, 1)[1])\n",
    "            loss5 = criterion(out5, torch.max(labels5, 1)[1])\n",
    "            loss = (loss1+loss2+loss3+loss4+loss5)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
    "            if (i+1) % 100 == 0:\n",
    "                torch.save(cnn.state_dict(), \"./model_trans.pkl\")   #current is model.pkl\n",
    "                print(\"save model\")\n",
    "            if min_loss > loss.item():\n",
    "                min_loss = loss.item()\n",
    "                torch.save(cnn.state_dict(), \"./model_trans_best.pkl\")   #current is model.pkl\n",
    "                print(\"save best model\")\n",
    "        print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
    "    torch.save(cnn.state_dict(), \"./model_trans.pkl\")   #current is model.pkl\n",
    "    print(\"save last model\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import pytorch_dataset\n",
    "from pytorch_model import CNN\n",
    "\n",
    "# Hyper Parameters\n",
    "num_epochs = 10\n",
    "batch_size = 80\n",
    "learning_rate = 0.001\n",
    "use_cuda=True\n",
    "\n",
    "def main():\n",
    "    min_loss = 9999\n",
    "    device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "    cnn = CNN().to(device)\n",
    "    cnn.train()\n",
    "    cnn.load_state_dict(torch.load('model_trans_best.pkl'))\n",
    "    print('init net')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the Model\n",
    "    train_dataloader = pytorch_dataset.get_train_data_loader()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            images = Variable(images).to(device)\n",
    "            labels1 = Variable(labels['label1'].float()).to(device)\n",
    "            labels2 = Variable(labels['label2'].float()).to(device)\n",
    "            labels3 = Variable(labels['label3'].float()).to(device)\n",
    "            labels4 = Variable(labels['label4'].float()).to(device)\n",
    "            labels5 = Variable(labels['label5'].float()).to(device)\n",
    "            out1,out2,out3,out4, out5 = cnn(images)\n",
    "            #out = cnn(images)\n",
    "\n",
    "            # print(predict_labels.type)\n",
    "            # print(labels.type)\n",
    "            loss1 = criterion(out1, torch.max(labels1, 1)[1])\n",
    "            loss2 = criterion(out2, torch.max(labels2, 1)[1])\n",
    "            loss3 = criterion(out3, torch.max(labels3, 1)[1])\n",
    "            loss4 = criterion(out4, torch.max(labels4, 1)[1])\n",
    "            loss5 = criterion(out5, torch.max(labels5, 1)[1])\n",
    "            loss = (loss1+loss2+loss3+loss4+loss5)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
    "            if (i+1) % 100 == 0:\n",
    "                torch.save(cnn.state_dict(), \"./model_3.pkl\")   #current is model.pkl\n",
    "                print(\"save model\")\n",
    "            if min_loss > loss.item():\n",
    "                min_loss = loss.item()\n",
    "                torch.save(cnn.state_dict(), \"./model_3_best.pkl\")   #current is model.pkl\n",
    "                print(\"save best model\")\n",
    "        print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
    "    torch.save(cnn.state_dict(), \"./model_3.pkl\")   #current is model.pkl\n",
    "    print(\"save last model\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import pytorch_dataset\n",
    "from pytorch_model import CNN\n",
    "\n",
    "# Hyper Parameters\n",
    "num_epochs = 300\n",
    "batch_size = 80\n",
    "learning_rate = 0.001\n",
    "use_cuda=True\n",
    "\n",
    "def main():\n",
    "    min_loss = 9999\n",
    "    device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "    cnn = CNN().to(device)\n",
    "    cnn.train()\n",
    "    cnn.load_state_dict(torch.load('model_3_best.pkl'))\n",
    "    print('init net')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the Model\n",
    "    train_dataloader = pytorch_dataset.get_transfer_data_loader()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            images = Variable(images).to(device)\n",
    "            labels1 = Variable(labels['label1'].float()).to(device)\n",
    "            labels2 = Variable(labels['label2'].float()).to(device)\n",
    "            labels3 = Variable(labels['label3'].float()).to(device)\n",
    "            labels4 = Variable(labels['label4'].float()).to(device)\n",
    "            labels5 = Variable(labels['label5'].float()).to(device)\n",
    "            out1,out2,out3,out4, out5 = cnn(images)\n",
    "            #out = cnn(images)\n",
    "\n",
    "            # print(predict_labels.type)\n",
    "            # print(labels.type)\n",
    "            loss1 = criterion(out1, torch.max(labels1, 1)[1])\n",
    "            loss2 = criterion(out2, torch.max(labels2, 1)[1])\n",
    "            loss3 = criterion(out3, torch.max(labels3, 1)[1])\n",
    "            loss4 = criterion(out4, torch.max(labels4, 1)[1])\n",
    "            loss5 = criterion(out5, torch.max(labels5, 1)[1])\n",
    "            loss = (loss1+loss2+loss3+loss4+loss5)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
    "            if (i+1) % 100 == 0:\n",
    "                torch.save(cnn.state_dict(), \"./model_trans_2.pkl\")   #current is model.pkl\n",
    "                print(\"save model\")\n",
    "            if min_loss > loss.item():\n",
    "                min_loss = loss.item()\n",
    "                torch.save(cnn.state_dict(), \"./model_trans_2_best.pkl\")   #current is model.pkl\n",
    "                print(\"save best model\")\n",
    "        print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
    "    torch.save(cnn.state_dict(), \"./model_trans_2.pkl\")   #current is model.pkl\n",
    "    print(\"save last model\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cnn net.\n",
      "Wronse answer ! Predict: g7c6p , Truth: 67c6p \n",
      "Wronse answer ! Predict: q69e7 , Truth: q6ge7 \n",
      "Wronse answer ! Predict: cnarp , Truth: rnarp \n",
      "Wronse answer ! Predict: bgy3a , Truth: hgy3a \n",
      "Wronse answer ! Predict: hdqdn , Truth: bdqdn \n",
      "Wronse answer ! Predict: 2ddyp , Truth: mddrz \n",
      "Wronse answer ! Predict: zdzzh , Truth: cazzh \n",
      "Wronse answer ! Predict: q2zxp , Truth: g2zxp \n",
      "Wronse answer ! Predict: 8r48g , Truth: 8rz8g \n",
      "Wronse answer ! Predict: fujcg , Truth: fujcq \n",
      "Wronse answer ! Predict: pmcc4 , Truth: pmcy4 \n",
      "Wronse answer ! Predict: peddb , Truth: puddb \n",
      "Wronse answer ! Predict: tex7g , Truth: tex7q \n",
      "Wronse answer ! Predict: eqbyy , Truth: eghyy \n",
      "Wronse answer ! Predict: udzg6 , Truth: udzq6 \n",
      "Wronse answer ! Predict: janfx , Truth: nanfx \n",
      "Wronse answer ! Predict: ezr6m , Truth: qzr6m \n",
      "Wronse answer ! Predict: eg3mr , Truth: e93m3 \n",
      "Wronse answer ! Predict: ba7pu , Truth: ha7pu \n",
      "Wronse answer ! Predict: 96g2g , Truth: m6g2g \n",
      "Wronse answer ! Predict: u46bq , Truth: u46ba \n",
      "Wronse answer ! Predict: 9mtdc , Truth: qmtdc \n",
      "Wronse answer ! Predict: 4mmmh , Truth: ummmh \n",
      "Wronse answer ! Predict: qbqpq , Truth: qbgpa \n",
      "Wronse answer ! Predict: mmmxy , Truth: mmmxb \n",
      "Wronse answer ! Predict: 2etme , Truth: 2utme \n",
      "Wronse answer ! Predict: tnpah , Truth: tnpad \n",
      "Wronse answer ! Predict: ubypu , Truth: uhypu \n",
      "Wronse answer ! Predict: emc7g , Truth: emc7a \n",
      "Wronse answer ! Predict: mqb8u , Truth: muh8u \n",
      "Wronse answer ! Predict: beqpb , Truth: begpb \n",
      "Wronse answer ! Predict: bzeuq , Truth: hzeuq \n",
      "Wronse answer ! Predict: tguqd , Truth: t9uqd \n",
      "Wronse answer ! Predict: bhmqy , Truth: xhmqy \n",
      "Wronse answer ! Predict: zgyaj , Truth: zgjaj \n",
      "Wronse answer ! Predict: 7lj6a , Truth: 7cj6a \n",
      "Wronse answer ! Predict: 2euep , Truth: 3euep \n",
      "Wronse answer ! Predict: rghm7 , Truth: rqhm7 \n",
      "Wronse answer ! Predict: mee9e , Truth: mtene \n",
      "Wronse answer ! Predict: b4mzp , Truth: b4mzg \n",
      "Wronse answer ! Predict: qyehe , Truth: qyghe \n",
      "Wronse answer ! Predict: ca8p2 , Truth: aa8p2 \n",
      "Wronse answer ! Predict: eha8z , Truth: ehh8z \n",
      "Wronse answer ! Predict: dg6qh , Truth: dg6qb \n",
      "Wronse answer ! Predict: mhtbr , Truth: mhthr \n",
      "Wronse answer ! Predict: 4y8by , Truth: 4y8bz \n",
      "Wronse answer ! Predict: 8te9a , Truth: 8tega \n",
      "Wronse answer ! Predict: 9qm3a , Truth: nqn3a \n",
      "Wronse answer ! Predict: ftubn , Truth: ftcbn \n",
      "Wronse answer ! Predict: tqtn2 , Truth: tqtnn \n",
      "accuracy = 75.00% \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "#from visdom import Visdom # pip install Visdom\n",
    "import pytorch_dataset\n",
    "from pytorch_model import CNN\n",
    "\n",
    "LETTERSTR = \"2346789abcdefghjklmnpqrtuxyz\"\n",
    "\n",
    "def main():\n",
    "    cnn = CNN()\n",
    "    cnn.eval()\n",
    "    cnn.load_state_dict(torch.load('model_trans.pkl'))\n",
    "    print(\"load cnn net.\")\n",
    "    correct_num = 0\n",
    "    step = 0.0\n",
    "    predict_dataloader = pytorch_dataset.get_predict_data_loader()\n",
    "\n",
    "    #vis = Visdom()\n",
    "    for i, (images, labels) in enumerate(predict_dataloader):\n",
    "        flag = False\n",
    "        image = images\n",
    "        vimage = Variable(image)\n",
    "        out1,out2,out3,out4,out5 = cnn(vimage)\n",
    "        labels1 = Variable(labels['label1'].float())\n",
    "        labels2 = Variable(labels['label2'].float())\n",
    "        labels3 = Variable(labels['label3'].float())\n",
    "        labels4 = Variable(labels['label4'].float())\n",
    "        labels5 = Variable(labels['label5'].float())\n",
    "        l0 = LETTERSTR[torch.max(labels1, 1)[1]]\n",
    "        l1 = LETTERSTR[torch.max(labels2, 1)[1]]\n",
    "        l2 = LETTERSTR[torch.max(labels3, 1)[1]]\n",
    "        l3 = LETTERSTR[torch.max(labels4, 1)[1]]\n",
    "        l4 = LETTERSTR[torch.max(labels5, 1)[1]]\n",
    "        \n",
    "        c0 = LETTERSTR[torch.max(out1, 1)[1]]\n",
    "        c1 = LETTERSTR[torch.max(out2, 1)[1]]\n",
    "        c2 = LETTERSTR[torch.max(out3, 1)[1]]\n",
    "        c3 = LETTERSTR[torch.max(out4, 1)[1]]\n",
    "        c4 = LETTERSTR[torch.max(out5, 1)[1]]\n",
    "        l = '%s%s%s%s%s' % (l0, l1, l2, l3, l4)\n",
    "        c = '%s%s%s%s%s' % (c0, c1, c2, c3, c4)\n",
    "        step += 1.0\n",
    "        correct_num += 1\n",
    "        \n",
    "        if l0 != c0 or l1 != c1 or l2 != c2 or l3 != c3 or l4 != c4 :\n",
    "            correct_num -= 1\n",
    "            flag = True\n",
    "        if flag :\n",
    "            print(\"Wronse answer ! Predict: %s , Truth: %s \"%(c,l))\n",
    "        #vis.images(image, opts=dict(caption=c))\n",
    "    accuracy = correct_num / step\n",
    "    print(\"accuracy = {:.2%} \".format(accuracy))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [0,1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(i[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.hstack((j,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "#from visdom import Visdom # pip install Visdom\n",
    "import pytorch_dataset\n",
    "from pytorch_model import CNN\n",
    "\n",
    "LETTERSTR = \"2346789abcdefghjklmnpqrtuxyz\"\n",
    "\n",
    "def main():\n",
    "    cnn = CNN()\n",
    "    cnn.eval()\n",
    "    cnn.load_state_dict(torch.load('captcha.pkl'))\n",
    "    print(\"load cnn net.\")\n",
    "    correct_num = 0\n",
    "    step = 0.0\n",
    "    predict_dataloader = pytorch_dataset.get_predict_data_loader()\n",
    "\n",
    "    #vis = Visdom()\n",
    "    for i, (images, labels) in enumerate(predict_dataloader):\n",
    "        flag = False\n",
    "        image = images\n",
    "        vimage = Variable(image)\n",
    "        out1,out2,out3,out4,out5 = cnn(vimage)\n",
    "        \n",
    "        c0 = LETTERSTR[torch.max(out1, 1)[1]]\n",
    "        c1 = LETTERSTR[torch.max(out2, 1)[1]]\n",
    "        c2 = LETTERSTR[torch.max(out3, 1)[1]]\n",
    "        c3 = LETTERSTR[torch.max(out4, 1)[1]]\n",
    "        c4 = LETTERSTR[torch.max(out5, 1)[1]]\n",
    "        c = '%s%s%s%s%s' % (c0, c1, c2, c3, c4)\n",
    "       \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
